{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "with open('breast-cancer-wisconsin.data.txt') as inputfile:\n",
    "    for line in inputfile:\n",
    "        if '?' in line:\n",
    "            continue\n",
    "        else:\n",
    "            result.append(line.rstrip().split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Data\t 683\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of Data\\t\",len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000025\n"
     ]
    }
   ],
   "source": [
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(result)):\n",
    "    rs = [int(j) for j in result[i]]\n",
    "    features.append(rs[1:10])\n",
    "    labels.append(rs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 1, 1, 1, 2, 1, 3, 1, 1], [5, 4, 4, 5, 7, 10, 3, 2, 1], [3, 1, 1, 1, 2, 2, 3, 1, 1], [6, 8, 8, 1, 3, 4, 3, 7, 1], [4, 1, 1, 3, 2, 1, 3, 1, 1], [8, 10, 10, 8, 7, 10, 9, 7, 1], [1, 1, 1, 1, 2, 10, 3, 1, 1], [2, 1, 2, 1, 2, 1, 3, 1, 1], [2, 1, 1, 1, 2, 1, 1, 1, 5], [4, 2, 1, 1, 2, 1, 2, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(features[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 4, 2, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0 if x==2 else x for x in labels]\n",
    "labels = [1 if x==4 else x for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical   \n",
    "\n",
    "labels = to_categorical(labels, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(features, labels, test_size = 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data  (457, 9)\n",
      "shape of test data (226, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of train data \", np.shape(X_train))\n",
    "print(\"shape of test data\", np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs =  20\n",
    "batch_size = 32\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden1 = 256\n",
    "n_hidden2 = 512\n",
    "n_hidden3 = 256\n",
    "n_classes = 2\n",
    "n_input = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder('float',[None,n_input])\n",
    "Y = tf.placeholder('float',[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([n_input,n_hidden1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden1,n_hidden2])),\n",
    "    'h3':tf.Variable(tf.random_normal([n_hidden2,n_hidden3])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden3,n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden2])),\n",
    "    'b3':tf.Variable(tf.random_normal([n_hidden3])),\n",
    "    'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    layer_3 = tf.add(tf.matmul(layer_2,weights['h3']),biases['b3'])\n",
    "    out_layer = tf.matmul(layer_3,weights['out'])+biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = multilayer_perceptron(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_batch(batch_size, features, labels):\n",
    "    idx = np.arange(0, len(features))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:batch_size]\n",
    "    data = [features[i] for i in idx]\n",
    "    labl = [labels[i] for i in idx]\n",
    "    return np.asarray(data), np.asarray(labl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost=46987.577933175\n",
      "Epoch: 0002 cost=10734.254525321\n",
      "Epoch: 0003 cost=5940.571105957\n",
      "Epoch: 0004 cost=4529.269208636\n",
      "Epoch: 0005 cost=4846.374585833\n",
      "Epoch: 0006 cost=3386.833833967\n",
      "Epoch: 0007 cost=2329.597255162\n",
      "Epoch: 0008 cost=1579.664975848\n",
      "Epoch: 0009 cost=2142.185793195\n",
      "Epoch: 0010 cost=1690.824626378\n",
      "Epoch: 0011 cost=1398.393345424\n",
      "Epoch: 0012 cost=1120.690298898\n",
      "Epoch: 0013 cost=852.983777727\n",
      "Epoch: 0014 cost=1115.431108747\n",
      "Epoch: 0015 cost=505.447014945\n",
      "Epoch: 0016 cost=310.587127686\n",
      "Epoch: 0017 cost=358.258178711\n",
      "Epoch: 0018 cost=228.025573730\n",
      "Epoch: 0019 cost=98.662384033\n",
      "Epoch: 0020 cost=96.829952861\n",
      "Epoch: 0021 cost=31.469142369\n",
      "Epoch: 0022 cost=40.490971157\n",
      "Epoch: 0023 cost=97.901951109\n",
      "Epoch: 0024 cost=26.304761614\n",
      "Epoch: 0025 cost=98.672197614\n",
      "Epoch: 0026 cost=127.872752598\n",
      "Epoch: 0027 cost=31.050545831\n",
      "Epoch: 0028 cost=81.843418666\n",
      "Epoch: 0029 cost=64.474905831\n",
      "Epoch: 0030 cost=84.130972794\n",
      "Epoch: 0031 cost=77.745837075\n",
      "Epoch: 0032 cost=48.200435093\n",
      "Epoch: 0033 cost=77.954830217\n",
      "Epoch: 0034 cost=61.697832382\n",
      "Epoch: 0035 cost=70.137956892\n",
      "Epoch: 0036 cost=40.251560756\n",
      "Epoch: 0037 cost=75.115975537\n",
      "Epoch: 0038 cost=86.439525750\n",
      "Epoch: 0039 cost=78.747594561\n",
      "Epoch: 0040 cost=89.185897555\n",
      "Optimization Finished!\n",
      "Accuracy: 0.96460176\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int((np.shape(X_train)[0]/batch_size))\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = get_next_batch(batch_size, X_train, Y_train)\n",
    "            _,c = sess.run([train_op, loss_op], feed_dict={X:batch_x, Y:batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    \n",
    "    pred = tf.nn.softmax(logits)  \n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
